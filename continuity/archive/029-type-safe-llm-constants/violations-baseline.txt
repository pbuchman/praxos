=== LLM Architecture Verification ===

Rule 1: Checking for unauthorized LLMClient implementations...
Rule 2: Checking if clients log usage...
Rule 3: Checking for hardcoded cost values in apps/...
Rule 4: Checking for hardcoded model strings...
Rule 5: Checking for hardcoded provider strings...

Found 1060 violation(s):


--- RULE-4 (703 violations) ---
  apps/actions-agent/src/__tests__/infra/research/ResearchAgentClient.test.ts:33
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/actions-agent/src/__tests__/infra/research/ResearchAgentClient.test.ts:33
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/actions-agent/src/__tests__/infra/research/ResearchAgentClient.test.ts:48
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'claude-opus-4-5-20251101'],
  apps/actions-agent/src/__tests__/infra/research/ResearchAgentClient.test.ts:48
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'claude-opus-4-5-20251101'],
  apps/actions-agent/src/__tests__/infra/research/ResearchAgentClient.test.ts:58
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'claude-opus-4-5-20251101'],
  apps/actions-agent/src/__tests__/infra/research/ResearchAgentClient.test.ts:58
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'claude-opus-4-5-20251101'],
  apps/actions-agent/src/__tests__/infra/research/ResearchAgentClient.test.ts:73
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['o4-mini-deep-research'],
  apps/actions-agent/src/__tests__/infra/research/ResearchAgentClient.test.ts:95
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['o4-mini-deep-research'],
  apps/actions-agent/src/__tests__/infra/research/ResearchAgentClient.test.ts:114
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['o4-mini-deep-research'],
  apps/actions-agent/src/__tests__/infra/research/ResearchAgentClient.test.ts:133
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['o4-mini-deep-research'],
  apps/actions-agent/src/__tests__/infra/research/ResearchAgentClient.test.ts:150
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['o4-mini-deep-research'],
  apps/actions-agent/src/domain/usecases/executeResearchAction.ts:56
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > const selectedModels: SupportedModel[] = ['claude-opus-4-5-20251101'];
  apps/app-settings-service/src/__tests__/infra/FirestorePricingRepository.test.ts:23
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > 'gemini-2.5-pro': {
  apps/app-settings-service/src/__tests__/infra/FirestorePricingRepository.test.ts:42
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > const geminiPricing = result?.models['gemini-2.5-pro'];
  apps/app-settings-service/src/__tests__/routes/internalRoutes.test.ts:14
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > 'gemini-2.5-pro': {
  apps/app-settings-service/src/__tests__/routes/internalRoutes.test.ts:26
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > 'gpt-5.2': {
  apps/app-settings-service/src/__tests__/routes/internalRoutes.test.ts:37
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > 'claude-opus-4-5-20251101': {
  apps/app-settings-service/src/__tests__/routes/internalRoutes.test.ts:48
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > 'sonar-pro': {
  apps/app-settings-service/src/__tests__/routes/internalRoutes.test.ts:108
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > expect(body.data.google.models['gemini-2.5-pro'].inputPricePerMillion).toBe(1.25);
  apps/commands-router/src/__tests__/infra/classifier.test.ts:310
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > expect(classificationResult.selectedModels).toEqual(['gemini-2.5-flash']);
  apps/commands-router/src/__tests__/infra/classifier.test.ts:330
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > 'gemini-2.5-pro',
  apps/commands-router/src/__tests__/infra/classifier.test.ts:331
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > 'claude-opus-4-5-20251101',
  apps/commands-router/src/__tests__/infra/classifier.test.ts:332
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > 'gpt-5.2',
  apps/commands-router/src/__tests__/infra/classifier.test.ts:333
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > 'sonar-pro',
  apps/commands-router/src/__tests__/infra/classifier.test.ts:339
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > 'gemini-2.5-pro',
  apps/commands-router/src/__tests__/infra/classifier.test.ts:340
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > 'claude-opus-4-5-20251101',
  apps/commands-router/src/__tests__/infra/classifier.test.ts:341
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > 'gpt-5.2',
  apps/commands-router/src/__tests__/infra/classifier.test.ts:342
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > 'sonar-pro',
  apps/commands-router/src/__tests__/infra/classifier.test.ts:348
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > 'gemini-2.5-pro',
  apps/commands-router/src/__tests__/infra/classifier.test.ts:349
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > 'claude-opus-4-5-20251101',
  apps/commands-router/src/__tests__/infra/classifier.test.ts:350
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > 'gpt-5.2',
  apps/commands-router/src/__tests__/infra/classifier.test.ts:351
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > 'sonar-pro',
  apps/commands-router/src/__tests__/infra/classifier.test.ts:357
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > 'gemini-2.5-pro',
  apps/commands-router/src/__tests__/infra/classifier.test.ts:358
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > 'claude-opus-4-5-20251101',
  apps/commands-router/src/__tests__/infra/classifier.test.ts:359
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > 'gpt-5.2',
  apps/commands-router/src/__tests__/infra/classifier.test.ts:360
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > 'sonar-pro',
  apps/commands-router/src/__tests__/infra/classifier.test.ts:367
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > expect(extractSelectedModels('use gemini for this')).toEqual(['gemini-2.5-flash']);
  apps/commands-router/src/__tests__/infra/classifier.test.ts:371
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > expect(extractSelectedModels('ask gpt about this')).toEqual(['gpt-5.2']);
  apps/commands-router/src/__tests__/infra/classifier.test.ts:375
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > expect(extractSelectedModels('ask chatgpt about this')).toEqual(['gpt-5.2']);
  apps/commands-router/src/__tests__/infra/classifier.test.ts:380
    Hardcoded model string 'claude-sonnet-4-5-20250929'. Use LlmModels constant instead.
    > 'claude-sonnet-4-5-20250929',
  apps/commands-router/src/__tests__/infra/classifier.test.ts:386
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > expect(result).toContain('gpt-5.2');
  apps/commands-router/src/__tests__/infra/classifier.test.ts:387
    Hardcoded model string 'claude-sonnet-4-5-20250929'. Use LlmModels constant instead.
    > expect(result).toContain('claude-sonnet-4-5-20250929');
  apps/commands-router/src/__tests__/infra/classifier.test.ts:392
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > expect(result).toContain('gemini-2.5-flash');
  apps/commands-router/src/__tests__/infra/classifier.test.ts:393
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > expect(result).toContain('gpt-5.2');
  apps/commands-router/src/__tests__/infra/classifier.test.ts:394
    Hardcoded model string 'claude-sonnet-4-5-20250929'. Use LlmModels constant instead.
    > expect(result).toContain('claude-sonnet-4-5-20250929');
  apps/commands-router/src/__tests__/infra/pubsub/actionEventPublisher.test.ts:57
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'claude-opus-4-5-20251101'],
  apps/commands-router/src/__tests__/infra/pubsub/actionEventPublisher.test.ts:57
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'claude-opus-4-5-20251101'],
  apps/commands-router/src/__tests__/infra/pubsub/actionEventPublisher.test.ts:159
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/commands-router/src/__tests__/infra/pubsub/actionEventPublisher.test.ts:159
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/commands-router/src/__tests__/infra/pubsub/actionEventPublisher.test.ts:159
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/commands-router/src/__tests__/infra/pubsub/actionEventPublisher.test.ts:171
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > 'gemini-2.5-pro',
  apps/commands-router/src/__tests__/infra/pubsub/actionEventPublisher.test.ts:172
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > 'o4-mini-deep-research',
  apps/commands-router/src/__tests__/infra/pubsub/actionEventPublisher.test.ts:173
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > 'claude-opus-4-5-20251101',
  apps/commands-router/src/__tests__/routes.test.ts:1033
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-flash', 'claude-sonnet-4-5-20250929'],
  apps/commands-router/src/__tests__/routes.test.ts:1033
    Hardcoded model string 'claude-sonnet-4-5-20250929'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-flash', 'claude-sonnet-4-5-20250929'],
  apps/commands-router/src/__tests__/routes.test.ts:1058
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > 'gemini-2.5-flash',
  apps/commands-router/src/__tests__/routes.test.ts:1059
    Hardcoded model string 'claude-sonnet-4-5-20250929'. Use LlmModels constant instead.
    > 'claude-sonnet-4-5-20250929',
  apps/commands-router/src/__tests__/routes.test.ts:1329
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-flash', 'claude-sonnet-4-5-20250929'],
  apps/commands-router/src/__tests__/routes.test.ts:1329
    Hardcoded model string 'claude-sonnet-4-5-20250929'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-flash', 'claude-sonnet-4-5-20250929'],
  apps/commands-router/src/__tests__/routes.test.ts:1344
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > 'gemini-2.5-flash',
  apps/commands-router/src/__tests__/routes.test.ts:1345
    Hardcoded model string 'claude-sonnet-4-5-20250929'. Use LlmModels constant instead.
    > 'claude-sonnet-4-5-20250929',
  apps/commands-router/src/__tests__/usecases/retryPendingCommands.test.ts:170
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-flash', 'o4-mini-deep-research'],
  apps/commands-router/src/__tests__/usecases/retryPendingCommands.test.ts:170
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-flash', 'o4-mini-deep-research'],
  apps/commands-router/src/__tests__/usecases/retryPendingCommands.test.ts:187
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > 'gemini-2.5-flash',
  apps/commands-router/src/__tests__/usecases/retryPendingCommands.test.ts:188
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > 'o4-mini-deep-research',
  apps/commands-router/src/infra/gemini/classifier.ts:51
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > 'gemini-2.5-pro': ['gemini pro', 'gemini-pro'],
  apps/commands-router/src/infra/gemini/classifier.ts:52
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > 'gemini-2.5-flash': ['gemini flash', 'gemini-flash', 'gemini', 'google'],
  apps/commands-router/src/infra/gemini/classifier.ts:53
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > 'claude-opus-4-5-20251101': ['claude opus', 'opus'],
  apps/commands-router/src/infra/gemini/classifier.ts:54
    Hardcoded model string 'claude-sonnet-4-5-20250929'. Use LlmModels constant instead.
    > 'claude-sonnet-4-5-20250929': ['claude sonnet', 'sonnet', 'claude', 'anthropic'],
  apps/commands-router/src/infra/gemini/classifier.ts:55
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > 'o4-mini-deep-research': ['o4', 'o4-mini', 'deep research'],
  apps/commands-router/src/infra/gemini/classifier.ts:56
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > 'gpt-5.2': ['gpt', 'gpt-5', 'openai', 'chatgpt'],
  apps/commands-router/src/infra/gemini/classifier.ts:58
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > 'sonar-pro': ['sonar', 'sonar pro', 'pplx', 'perplexity'],
  apps/commands-router/src/infra/gemini/classifier.ts:58
    Hardcoded model string 'sonar'. Use LlmModels constant instead.
    > 'sonar-pro': ['sonar', 'sonar pro', 'pplx', 'perplexity'],
  apps/commands-router/src/infra/gemini/classifier.ts:59
    Hardcoded model string 'sonar-deep-research'. Use LlmModels constant instead.
    > 'sonar-deep-research': ['sonar deep', 'perplexity deep', 'deep sonar'],
  apps/commands-router/src/infra/gemini/classifier.ts:63
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > 'gemini-2.5-pro',
  apps/commands-router/src/infra/gemini/classifier.ts:64
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > 'claude-opus-4-5-20251101',
  apps/commands-router/src/infra/gemini/classifier.ts:65
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > 'gpt-5.2',
  apps/commands-router/src/infra/gemini/classifier.ts:66
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > 'sonar-pro',
  apps/commands-router/src/infra/gemini/classifier.ts:104
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > const CLASSIFIER_MODEL = 'gemini-2.5-flash';
  apps/data-insights-service/src/index.ts:24
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > const REQUIRED_MODELS = ['gemini-2.5-flash'] as const;
  apps/data-insights-service/src/infra/gemini/feedNameGenerationService.ts:18
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > const NAME_GENERATION_MODEL: FastModel = 'gemini-2.5-flash';
  apps/data-insights-service/src/infra/gemini/titleGenerationService.ts:14
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > const TITLE_GENERATION_MODEL: FastModel = 'gemini-2.5-flash';
  apps/image-service/src/__tests__/FakeImageGenerator.test.ts:8
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/image-service/src/__tests__/FakeImageGenerator.test.ts:18
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > expect(result.value.model).toBe('gpt-image-1');
  apps/image-service/src/__tests__/FakeImageGenerator.test.ts:32
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > model: 'gemini-2.5-flash-image',
  apps/image-service/src/__tests__/FakeImageGenerator.test.ts:48
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > model: 'gemini-2.5-flash-image',
  apps/image-service/src/__tests__/FakeImageGenerator.test.ts:56
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > expect(result.value.model).toBe('gemini-2.5-flash-image');
  apps/image-service/src/__tests__/FakeImageGenerator.test.ts:63
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/image-service/src/__tests__/FakeImageGenerator.test.ts:84
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/image-service/src/__tests__/GeminiPromptAdapter.test.ts:177
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/image-service/src/__tests__/fakes.ts:221
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/image-service/src/__tests__/infra/GoogleImageGenerator.test.ts:57
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > const testModel = 'gemini-2.5-flash-image' as const;
  apps/image-service/src/__tests__/infra/GoogleImageGenerator.test.ts:75
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > model: 'gemini-2.5-flash-image',
  apps/image-service/src/__tests__/infra/GoogleImageGenerator.test.ts:117
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > model: 'gemini-2.5-flash-image',
  apps/image-service/src/__tests__/infra/GoogleImageGenerator.test.ts:147
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > model: 'gemini-2.5-flash-image',
  apps/image-service/src/__tests__/infra/GoogleImageGenerator.test.ts:206
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > model: 'gemini-2.5-flash-image',
  apps/image-service/src/__tests__/infra/GoogleImageGenerator.test.ts:331
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > model: 'gemini-2.5-flash-image',
  apps/image-service/src/__tests__/infra/OpenAIImageGenerator.test.ts:57
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > const testModel = 'gpt-image-1' as const;
  apps/image-service/src/__tests__/infra/OpenAIImageGenerator.test.ts:75
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/image-service/src/__tests__/infra/OpenAIImageGenerator.test.ts:117
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/image-service/src/__tests__/infra/OpenAIImageGenerator.test.ts:147
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/image-service/src/__tests__/infra/OpenAIImageGenerator.test.ts:206
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/image-service/src/__tests__/infra/OpenAIImageGenerator.test.ts:333
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/image-service/src/__tests__/infra/firestore/generatedImageRepository.test.ts:14
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/image-service/src/__tests__/infra/firestore/generatedImageRepository.test.ts:44
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > expect(result.value.model).toBe('gpt-image-1');
  apps/image-service/src/__tests__/infra/firestore/generatedImageRepository.test.ts:52
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > model: 'gemini-2.5-flash-image',
  apps/image-service/src/__tests__/infra/firestore/generatedImageRepository.test.ts:61
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > expect(result.value.model).toBe('gemini-2.5-flash-image');
  apps/image-service/src/__tests__/internalRoutes.test.ts:230
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > model: 'gemini-2.5-pro',
  apps/image-service/src/__tests__/internalRoutes.test.ts:246
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/image-service/src/__tests__/internalRoutes.test.ts:261
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/image-service/src/__tests__/internalRoutes.test.ts:276
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/image-service/src/__tests__/internalRoutes.test.ts:306
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/image-service/src/__tests__/internalRoutes.test.ts:322
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/image-service/src/__tests__/internalRoutes.test.ts:339
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/image-service/src/__tests__/internalRoutes.test.ts:359
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/image-service/src/__tests__/internalRoutes.test.ts:377
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/image-service/src/__tests__/internalRoutes.test.ts:397
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/image-service/src/__tests__/internalRoutes.test.ts:426
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > model: 'gemini-2.5-flash-image',
  apps/image-service/src/__tests__/internalRoutes.test.ts:442
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/image-service/src/__tests__/models.test.ts:19
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > expect(IMAGE_PROMPT_MODELS['gemini-2.5-pro']).toEqual({
  apps/image-service/src/__tests__/models.test.ts:21
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > modelId: 'gemini-2.5-pro',
  apps/image-service/src/__tests__/models.test.ts:32
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > expect(isValidImagePromptModel('gemini-2.5-pro')).toBe(true);
  apps/image-service/src/__tests__/models.test.ts:48
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > expect(IMAGE_GENERATION_MODELS['gpt-image-1']).toEqual({
  apps/image-service/src/__tests__/models.test.ts:50
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > modelId: 'gpt-image-1',
  apps/image-service/src/__tests__/models.test.ts:55
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > expect(IMAGE_GENERATION_MODELS['gemini-2.5-flash-image']).toEqual({
  apps/image-service/src/__tests__/models.test.ts:57
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > modelId: 'gemini-2.5-flash-image',
  apps/image-service/src/__tests__/models.test.ts:64
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > expect(isValidImageGenerationModel('gpt-image-1')).toBe(true);
  apps/image-service/src/__tests__/models.test.ts:68
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > expect(isValidImageGenerationModel('gemini-2.5-flash-image')).toBe(true);
  apps/image-service/src/__tests__/services.test.ts:97
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > const generator = services.createImageGenerator('gpt-image-1', 'test-key', 'test-user-id');
  apps/image-service/src/__tests__/services.test.ts:108
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > 'gemini-2.5-flash-image',
  apps/image-service/src/domain/models/ImageGenerationModel.ts:1
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > export type ImageGenerationModel = 'gpt-image-1' | 'gemini-2.5-flash-image';
  apps/image-service/src/domain/models/ImageGenerationModel.ts:1
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > export type ImageGenerationModel = 'gpt-image-1' | 'gemini-2.5-flash-image';
  apps/image-service/src/domain/models/ImageGenerationModel.ts:9
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > 'gpt-image-1': { provider: 'openai', modelId: 'gpt-image-1' },
  apps/image-service/src/domain/models/ImageGenerationModel.ts:10
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > 'gemini-2.5-flash-image': { provider: 'google', modelId: 'gemini-2.5-flash-image' },
  apps/image-service/src/domain/models/ImagePromptModel.ts:2
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > export type ImagePromptModel = 'gpt-4.1' | 'gemini-2.5-pro';
  apps/image-service/src/domain/models/ImagePromptModel.ts:11
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > 'gemini-2.5-pro': { provider: 'google', modelId: 'gemini-2.5-pro' },
  apps/image-service/src/index.ts:26
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > 'gemini-2.5-flash',       // Prompt generation
  apps/image-service/src/index.ts:27
    Hardcoded model string 'gpt-4o-mini'. Use LlmModels constant instead.
    > 'gpt-4o-mini',            // Prompt generation
  apps/image-service/src/index.ts:28
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > 'gpt-image-1',            // Image generation
  apps/image-service/src/index.ts:29
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > 'gemini-2.5-flash-image', // Image generation
  apps/image-service/src/infra/image/GoogleImageGenerator.ts:51
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > model: 'gemini-2.5-flash-image',
  apps/image-service/src/infra/llm/GeminiPromptAdapter.ts:15
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > const DEFAULT_MODEL = 'gemini-2.5-pro';
  apps/image-service/src/routes/schemas/imageSchemas.ts:13
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > enum: ['gpt-image-1', 'gemini-2.5-flash-image'],
  apps/image-service/src/routes/schemas/imageSchemas.ts:13
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > enum: ['gpt-image-1', 'gemini-2.5-flash-image'],
  apps/image-service/src/routes/schemas/imageSchemas.ts:62
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > model: 'gpt-image-1' | 'gemini-2.5-flash-image';
  apps/image-service/src/routes/schemas/imageSchemas.ts:62
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1' | 'gemini-2.5-flash-image';
  apps/image-service/src/routes/schemas/promptSchemas.ts:13
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > enum: ['gpt-4.1', 'gemini-2.5-pro'],
  apps/image-service/src/routes/schemas/promptSchemas.ts:74
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > model: 'gpt-4.1' | 'gemini-2.5-pro';
  apps/image-service/src/services.ts:73
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > const geminiPricing = pricingContext.getPricing('gemini-2.5-flash');
  apps/image-service/src/services.ts:74
    Hardcoded model string 'gpt-4o-mini'. Use LlmModels constant instead.
    > const gptPricing = pricingContext.getPricing('gpt-4o-mini');
  apps/image-service/src/services.ts:77
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > const openaiImagePricing = pricingContext.getPricing('gpt-image-1');
  apps/image-service/src/services.ts:78
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > const googleImagePricing = pricingContext.getPricing('gemini-2.5-flash-image');
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:43
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:43
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:44
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:46
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.5-pro', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:47
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:88
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.5-pro', status: 'completed', result: 'Result' },
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:89
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:103
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.5-pro', status: 'completed', result: 'Result' },
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:104
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'processing' },
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:120
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > model: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:126
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > model: 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:143
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.5-pro', status: 'failed', error: 'API Error' },
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:146
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > model: 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:169
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > model: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:175
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > model: 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:185
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > expect(result).toEqual({ type: 'partial_failure', failedModels: ['o4-mini-deep-research'] });
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:189
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > failedModels: ['o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:199
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > failedModels: ['o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:206
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > model: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:212
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > model: 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:222
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > expect(result).toEqual({ type: 'partial_failure', failedModels: ['o4-mini-deep-research'] });
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:226
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > failedModels: ['o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:235
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:235
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:235
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:239
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > model: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:243
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'failed', error: 'Error 1' },
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:246
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > model: 'claude-opus-4-5-20251101',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:258
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > failedModels: ['o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:258
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > failedModels: ['o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:264
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:268
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > model: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:272
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:273
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > { provider: 'anthropic', model: 'claude-opus-4-5-20251101', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:45
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:45
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:46
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:50
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:56
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > model: 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:84
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > additionalModels: ['claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:103
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > additionalModels: ['claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:121
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > additionalModels: ['claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:139
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > additionalModels: ['claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:176
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > additionalModels: ['claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:185
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > expect(result.value.selectedModels).toContain('claude-opus-4-5-20251101');
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:199
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > synthesisModel: 'claude-opus-4-5-20251101',
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:206
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > expect(result.value.synthesisModel).toBe('claude-opus-4-5-20251101');
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:259
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > additionalModels: ['claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:278
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > additionalModels: ['claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:279
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-flash',
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:290
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > model: 'claude-opus-4-5-20251101',
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:302
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > model: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:311
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > model: 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:326
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > synthesisModel: 'claude-opus-4-5-20251101',
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:75
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:75
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:76
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:78
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:79
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:138
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > expect(deps.mockReportSuccess).toHaveBeenCalledWith('gemini-2.5-flash');
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:142
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > const research = createTestResearch({ synthesisModel: 'claude-opus-4-5-20251101' });
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:163
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > expect(mockReportSuccess).toHaveBeenCalledWith('claude-opus-4-5-20251101');
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:184
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:184
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:184
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:186
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:187
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:200
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:207
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > model: 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:221
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > selectedModels: ['claude-sonnet-4-5-20250929', 'gemini-2.5-flash'],
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:221
    Hardcoded model string 'claude-sonnet-4-5-20250929'. Use LlmModels constant instead.
    > selectedModels: ['claude-sonnet-4-5-20250929', 'gemini-2.5-flash'],
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:223
    Hardcoded model string 'claude-sonnet-4-5-20250929'. Use LlmModels constant instead.
    > { provider: 'anthropic', model: 'claude-sonnet-4-5-20250929', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:224
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.5-flash', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:232
    Hardcoded model string 'claude-sonnet-4-5-20250929'. Use LlmModels constant instead.
    > expect(calls[0]?.[0].model).toBe('claude-sonnet-4-5-20250929');
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:233
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > expect(calls[1]?.[0].model).toBe('gemini-2.5-flash');
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:238
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:238
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:238
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:240
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'completed', result: 'Existing' },
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:241
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:251
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > expect.objectContaining({ model: 'gemini-2.0-flash' })
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:254
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > expect.objectContaining({ model: 'o4-mini-deep-research' })
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:263
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:263
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:267
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:273
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > model: 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:411
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > expect(localReportSuccess).toHaveBeenCalledWith('gemini-2.5-flash');
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:464
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > expect(localMockReportSuccess).not.toHaveBeenCalledWith('gemini-2.5-flash');
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:53
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:53
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:54
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:58
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:62
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'failed', error: 'Rate limit' },
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:65
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > failedModels: ['o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:120
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:120
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:121
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:125
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:131
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > model: 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:148
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > failedModels: ['o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:173
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:189
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > failedModels: ['o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:208
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > model: 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:221
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > retriedModels: ['o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:227
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:227
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:227
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:229
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.5-flash', status: 'completed', result: 'Result' },
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:230
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'failed', error: 'Error 1' },
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:233
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > model: 'claude-opus-4-5-20251101',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:239
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > failedModels: ['o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:239
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > failedModels: ['o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:250
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > retriedModels: ['o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:250
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > retriedModels: ['o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:259
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > failedModels: ['o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:80
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:80
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:81
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:85
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:91
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > model: 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:169
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'completed', result: 'Result' },
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:195
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:224
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > model: 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:238
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > retriedModels: ['o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:244
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:244
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:244
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:246
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'completed', result: 'Result' },
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:249
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > model: 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:255
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > model: 'claude-opus-4-5-20251101',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:268
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > retriedModels: ['o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:268
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > retriedModels: ['o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:282
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:304
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:325
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:346
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'completed', result: 'Result' },
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:76
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:76
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:77
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:81
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:87
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > model: 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:141
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'failed', error: 'Error' },
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:142
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'failed', error: 'Error' },
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:162
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:172
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'failed', error: 'Error' },
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:182
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > { model: 'gemini-2.0-flash', content: 'Google Result' },
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:295
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'completed' },
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:306
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > { model: 'gemini-2.0-flash', content: '' },
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:317
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:321
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:345
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:349
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'failed', error: 'Failed' },
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:363
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:367
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:390
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:396
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > model: 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:413
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'failed', error: 'Failed' },
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:430
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:434
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:454
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:458
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:522
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > { model: 'gemini-2.0-flash', content: 'Google Result' },
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:523
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > { model: 'o4-mini-deep-research', content: 'OpenAI Result' },
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:759
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:764
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > 'gemini-2.5-flash-image',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:816
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > 'gpt-image-1',
  apps/research-agent/src/__tests__/domain/research/usecases/unshareResearch.test.ts:56
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/domain/research/usecases/unshareResearch.test.ts:57
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/domain/research/utils/costCalculator.test.ts:63
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > model: 'sonar-pro',
  apps/research-agent/src/__tests__/domain/research/utils/costCalculator.test.ts:81
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > model: 'sonar-pro',
  apps/research-agent/src/__tests__/domain/research/utils/costCalculator.test.ts:100
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > model: 'sonar-pro',
  apps/research-agent/src/__tests__/domain/research/utils/costCalculator.test.ts:275
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > model: 'sonar-pro',
  apps/research-agent/src/__tests__/domain/research/utils/htmlGenerator.test.ts:88
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/domain/research/utils/htmlGenerator.test.ts:103
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > expect(html).toContain('gemini-2.0-flash');
  apps/research-agent/src/__tests__/domain/research/utils/htmlGenerator.test.ts:117
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/domain/research/utils/htmlGenerator.test.ts:129
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > expect(html).toContain('gemini-2.0-flash');
  apps/research-agent/src/__tests__/domain/research/utils/htmlGenerator.test.ts:139
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/infra/image/imageServiceClient.test.ts:61
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > model: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/infra/image/imageServiceClient.test.ts:67
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > const result = await client.generatePrompt('gemini text', 'gemini-2.5-pro', 'user-2');
  apps/research-agent/src/__tests__/infra/image/imageServiceClient.test.ts:110
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  apps/research-agent/src/__tests__/infra/image/imageServiceClient.test.ts:119
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > const result = await client.generateImage('A beautiful sunset', 'gpt-image-1', 'user-1');
  apps/research-agent/src/__tests__/infra/image/imageServiceClient.test.ts:131
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > model: 'gemini-2.5-flash-image',
  apps/research-agent/src/__tests__/infra/image/imageServiceClient.test.ts:140
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > 'gemini-2.5-flash-image',
  apps/research-agent/src/__tests__/infra/image/imageServiceClient.test.ts:154
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > const result = await client.generateImage('prompt', 'gpt-image-1', 'user-1');
  apps/research-agent/src/__tests__/infra/image/imageServiceClient.test.ts:167
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > const result = await client.generateImage('prompt', 'gpt-image-1', 'user-1');
  apps/research-agent/src/__tests__/infra/llm/ClaudeAdapter.test.ts:30
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > adapter = new ClaudeAdapter('test-key', 'claude-opus-4-5-20251101', 'test-user-id', testPricing);
  apps/research-agent/src/__tests__/infra/llm/ClaudeAdapter.test.ts:36
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > new ClaudeAdapter('test-key', 'claude-opus-4-5-20251101', 'test-user-id', testPricing);
  apps/research-agent/src/__tests__/infra/llm/ClaudeAdapter.test.ts:40
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > model: 'claude-opus-4-5-20251101',
  apps/research-agent/src/__tests__/infra/llm/ContextInferenceAdapter.test.ts:93
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > adapter = new ContextInferenceAdapter('test-key', 'gemini-2.0-flash', 'test-user', testPricing, mock...
  apps/research-agent/src/__tests__/infra/llm/ContextInferenceAdapter.test.ts:99
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > new ContextInferenceAdapter('test-key', 'gemini-2.0-flash', 'test-user', testPricing);
  apps/research-agent/src/__tests__/infra/llm/ContextInferenceAdapter.test.ts:103
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/infra/llm/GeminiAdapter.test.ts:34
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > adapter = new GeminiAdapter('test-key', 'gemini-2.5-pro', 'test-user-id', testPricing);
  apps/research-agent/src/__tests__/infra/llm/GeminiAdapter.test.ts:40
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > new GeminiAdapter('test-key', 'gemini-2.5-pro', 'test-user-id', testPricing);
  apps/research-agent/src/__tests__/infra/llm/GeminiAdapter.test.ts:44
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > model: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/infra/llm/GeminiAdapter.test.ts:51
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > const testAdapter = new GeminiAdapter('test-key', 'gemini-2.5-pro', 'test-user-id', testPricing);
  apps/research-agent/src/__tests__/infra/llm/GptAdapter.test.ts:32
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > adapter = new GptAdapter('test-key', 'o4-mini-deep-research', 'test-user-id', testPricing);
  apps/research-agent/src/__tests__/infra/llm/GptAdapter.test.ts:38
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > new GptAdapter('test-key', 'o4-mini-deep-research', 'test-user-id', testPricing);
  apps/research-agent/src/__tests__/infra/llm/GptAdapter.test.ts:42
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > model: 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/infra/llm/LlmAdapterFactory.test.ts:68
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > const provider = createResearchProvider('gemini-2.5-pro', 'google-key', 'test-user-id', testPricing)...
  apps/research-agent/src/__tests__/infra/llm/LlmAdapterFactory.test.ts:71
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > expect((provider as unknown as { model: string }).model).toBe('gemini-2.5-pro');
  apps/research-agent/src/__tests__/infra/llm/LlmAdapterFactory.test.ts:76
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > 'claude-opus-4-5-20251101',
  apps/research-agent/src/__tests__/infra/llm/LlmAdapterFactory.test.ts:83
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > expect((provider as unknown as { model: string }).model).toBe('claude-opus-4-5-20251101');
  apps/research-agent/src/__tests__/infra/llm/LlmAdapterFactory.test.ts:88
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/infra/llm/LlmAdapterFactory.test.ts:95
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > expect((provider as unknown as { model: string }).model).toBe('o4-mini-deep-research');
  apps/research-agent/src/__tests__/infra/llm/LlmAdapterFactory.test.ts:99
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > const provider = createResearchProvider('sonar-pro', 'perplexity-key', 'test-user-id', testPricing);
  apps/research-agent/src/__tests__/infra/llm/LlmAdapterFactory.test.ts:102
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > expect((provider as unknown as { model: string }).model).toBe('sonar-pro');
  apps/research-agent/src/__tests__/infra/llm/LlmAdapterFactory.test.ts:108
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > const synthesizer = createSynthesizer('gemini-2.5-pro', 'google-key', 'test-user-id', testPricing);
  apps/research-agent/src/__tests__/infra/llm/LlmAdapterFactory.test.ts:111
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > expect((synthesizer as unknown as { model: string }).model).toBe('gemini-2.5-pro');
  apps/research-agent/src/__tests__/infra/llm/LlmAdapterFactory.test.ts:116
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > createSynthesizer('claude-opus-4-5-20251101', 'anthropic-key', 'test-user-id', testPricing)
  apps/research-agent/src/__tests__/infra/llm/LlmAdapterFactory.test.ts:121
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > const synthesizer = createSynthesizer('o4-mini-deep-research', 'openai-key', 'test-user-id', testPri...
  apps/research-agent/src/__tests__/infra/llm/LlmAdapterFactory.test.ts:124
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > expect((synthesizer as unknown as { model: string }).model).toBe('o4-mini-deep-research');
  apps/research-agent/src/__tests__/infra/llm/LlmAdapterFactory.test.ts:128
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > expect(() => createSynthesizer('sonar-pro', 'perplexity-key', 'test-user-id', testPricing)).toThrow(
  apps/research-agent/src/__tests__/infra/llm/LlmAdapterFactory.test.ts:136
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > const generator = createTitleGenerator('gemini-2.0-flash', 'google-key', 'test-user-id', testPricing...
  apps/research-agent/src/__tests__/infra/llm/LlmAdapterFactory.test.ts:139
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > expect((generator as unknown as { model: string }).model).toBe('gemini-2.0-flash');
  apps/research-agent/src/__tests__/infra/llm/PerplexityAdapter.test.ts:27
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > adapter = new PerplexityAdapter('test-key', 'sonar-pro', 'test-user-id', testPricing);
  apps/research-agent/src/__tests__/infra/llm/PerplexityAdapter.test.ts:33
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > new PerplexityAdapter('test-key', 'sonar-pro', 'test-user-id', testPricing);
  apps/research-agent/src/__tests__/infra/llm/PerplexityAdapter.test.ts:37
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > model: 'sonar-pro',
  apps/research-agent/src/__tests__/infra/notification/WhatsAppNotificationSender.test.ts:132
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/infra/notification/WhatsAppNotificationSender.test.ts:139
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > message: expect.stringContaining('gemini-2.5-pro'),
  apps/research-agent/src/__tests__/infra/notification/WhatsAppNotificationSender.test.ts:148
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > await sender.sendLlmFailure('user-123', 'research-456', 'o4-mini-deep-research', 'Timeout');
  apps/research-agent/src/__tests__/infra/notification/WhatsAppNotificationSender.test.ts:152
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > message: expect.stringContaining('o4-mini-deep-research'),
  apps/research-agent/src/__tests__/infra/notification/WhatsAppNotificationSender.test.ts:164
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > 'claude-opus-4-5-20251101',
  apps/research-agent/src/__tests__/infra/notification/WhatsAppNotificationSender.test.ts:170
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > message: expect.stringContaining('claude-opus-4-5-20251101'),
  apps/research-agent/src/__tests__/infra/notification/WhatsAppNotificationSender.test.ts:182
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > 'gemini-2.5-flash',
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:22
    Hardcoded model string 'gpt-4o-mini'. Use LlmModels constant instead.
    > 'gpt-4o-mini': {
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:33
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > 'gemini-2.5-flash': {
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:176
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > const result = await client.getModelPricing('perplexity', 'sonar-pro');
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:200
    Hardcoded model string 'gpt-4o-mini'. Use LlmModels constant instead.
    > const result2 = await client.getModelPricing('openai', 'gpt-4o-mini');
  apps/research-agent/src/__tests__/infra/pricing/firestorePricingRepository.test.ts:40
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > const result = await repository.findByProviderAndModel('google', 'gemini-2.0-flash');
  apps/research-agent/src/__tests__/infra/pricing/firestorePricingRepository.test.ts:63
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > const result = await repository.findByProviderAndModel('google', 'gemini-2.0-flash');
  apps/research-agent/src/__tests__/infra/pubsub/llmCallPublisher.test.ts:40
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > model: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/infra/pubsub/llmCallPublisher.test.ts:71
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > const models = ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'] as const;
  apps/research-agent/src/__tests__/infra/pubsub/llmCallPublisher.test.ts:71
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > const models = ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'] as const;
  apps/research-agent/src/__tests__/infra/pubsub/llmCallPublisher.test.ts:71
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > const models = ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'] as const;
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:55
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro' as const],
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:56
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro' as const,
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:127
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:128
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:138
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:139
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:250
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:251
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:308
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:308
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:309
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:312
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.5-pro', status: 'pending' },
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:313
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > { provider: 'anthropic', model: 'claude-opus-4-5-20251101', status: 'pending' },
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:323
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > const result = await repository.updateLlmResult('research-1', 'gemini-2.5-pro', {
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:333
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > model: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:337
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > { provider: 'anthropic', model: 'claude-opus-4-5-20251101', status: 'pending' },
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:345
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > const result = await repository.updateLlmResult('nonexistent', 'gemini-2.0-flash', {
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:361
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:362
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:365
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'failed', error: 'Rate limit' },
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:375
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > const result = await repository.updateLlmResult('research-1', 'gemini-2.0-flash', {
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:384
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:397
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:398
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:401
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'failed', error: 'Rate limit' },
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:411
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > const result = await repository.updateLlmResult('research-1', 'gemini-2.0-flash', {
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:420
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:433
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:434
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:436
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > llmResults: [{ provider: 'google', model: 'gemini-2.0-flash', status: 'processing' }],
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:445
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > const result = await repository.updateLlmResult('research-1', 'gemini-2.0-flash', {
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:455
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:469
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:470
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:472
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > llmResults: [{ provider: 'google', model: 'gemini-2.0-flash', status: 'processing' }],
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:481
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > const result = await repository.updateLlmResult('research-1', 'gemini-2.0-flash', {
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:531
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:532
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/routes.test.ts:42
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/routes.test.ts:43
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/routes.test.ts:105
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/routes.test.ts:106
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/routes.test.ts:308
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/routes.test.ts:309
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/routes.test.ts:332
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/routes.test.ts:333
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > synthesisModel: 'claude-opus-4-5-20251101',
  apps/research-agent/src/__tests__/routes.test.ts:354
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/routes.test.ts:355
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/routes.test.ts:405
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/routes.test.ts:405
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/routes.test.ts:406
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > synthesisModel: 'claude-opus-4-5-20251101',
  apps/research-agent/src/__tests__/routes.test.ts:416
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > expect(saved.selectedModels).toEqual(['gemini-2.5-pro', 'o4-mini-deep-research']);
  apps/research-agent/src/__tests__/routes.test.ts:416
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > expect(saved.selectedModels).toEqual(['gemini-2.5-pro', 'o4-mini-deep-research']);
  apps/research-agent/src/__tests__/routes.test.ts:417
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > expect(saved.synthesisModel).toBe('claude-opus-4-5-20251101');
  apps/research-agent/src/__tests__/routes.test.ts:440
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/routes.test.ts:441
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > 'claude-opus-4-5-20251101',
  apps/research-agent/src/__tests__/routes.test.ts:442
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/routes.test.ts:444
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > expect(saved.synthesisModel).toBe('gemini-2.5-pro');
  apps/research-agent/src/__tests__/routes.test.ts:500
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > selectedModels: ['claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/routes.test.ts:501
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/routes.test.ts:509
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > expect(body.data.selectedModels).toEqual(['claude-opus-4-5-20251101']);
  apps/research-agent/src/__tests__/routes.test.ts:510
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > expect(body.data.synthesisModel).toBe('gemini-2.5-pro');
  apps/research-agent/src/__tests__/routes.test.ts:521
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/routes.test.ts:522
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > llmResults: [{ provider: 'google', model: 'gemini-2.5-pro', status: 'pending' }],
  apps/research-agent/src/__tests__/routes.test.ts:532
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/routes.test.ts:532
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > selectedModels: ['o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/routes.test.ts:539
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/routes.test.ts:540
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > 'claude-opus-4-5-20251101',
  apps/research-agent/src/__tests__/routes.test.ts:1082
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/routes.test.ts:1101
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > payload: { additionalModels: ['claude-opus-4-5-20251101'] },
  apps/research-agent/src/__tests__/routes.test.ts:1108
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > expect(body.data.selectedModels).toContain('claude-opus-4-5-20251101');
  apps/research-agent/src/__tests__/routes.test.ts:1118
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > payload: { additionalModels: ['claude-opus-4-5-20251101'] },
  apps/research-agent/src/__tests__/routes.test.ts:1136
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > payload: { additionalModels: ['claude-opus-4-5-20251101'] },
  apps/research-agent/src/__tests__/routes.test.ts:1154
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > payload: { additionalModels: ['claude-opus-4-5-20251101'] },
  apps/research-agent/src/__tests__/routes.test.ts:1190
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > payload: { synthesisModel: 'claude-opus-4-5-20251101' },
  apps/research-agent/src/__tests__/routes.test.ts:1196
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > expect(body.data.synthesisModel).toBe('claude-opus-4-5-20251101');
  apps/research-agent/src/__tests__/routes.test.ts:1246
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > payload: { additionalModels: ['claude-opus-4-5-20251101'] },
  apps/research-agent/src/__tests__/routes.test.ts:1344
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/routes.test.ts:1350
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > model: 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/routes.test.ts:1356
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > failedModels: ['o4-mini-deep-research'],
  apps/research-agent/src/__tests__/routes.test.ts:1409
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > expect(body.data.message).toContain('o4-mini-deep-research');
  apps/research-agent/src/__tests__/routes.test.ts:1501
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/routes.test.ts:1502
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/routes.test.ts:1505
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'completed', result: 'Result' },
  apps/research-agent/src/__tests__/routes.test.ts:1672
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > failedModels: ['o4-mini-deep-research'],
  apps/research-agent/src/__tests__/routes.test.ts:1708
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/routes.test.ts:1714
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > model: 'o4-mini-deep-research',
  apps/research-agent/src/__tests__/routes.test.ts:1742
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > expect(body.data.retriedModels).toContain('o4-mini-deep-research');
  apps/research-agent/src/__tests__/routes.test.ts:1755
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/routes.test.ts:1904
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/research-agent/src/__tests__/routes.test.ts:2052
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/routes.test.ts:2052
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/routes.test.ts:2063
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > expect(body.data.selectedModels).toEqual(['gemini-2.5-pro', 'o4-mini-deep-research']);
  apps/research-agent/src/__tests__/routes.test.ts:2063
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > expect(body.data.selectedModels).toEqual(['gemini-2.5-pro', 'o4-mini-deep-research']);
  apps/research-agent/src/__tests__/routes.test.ts:2075
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > selectedModels: ['claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/routes.test.ts:2094
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/routes.test.ts:2112
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/routes.test.ts:2132
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/routes.test.ts:2152
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/routes.test.ts:2430
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > model: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/routes.test.ts:2440
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/routes.test.ts:2440
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/routes.test.ts:2442
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.5-pro', status: 'pending' },
  apps/research-agent/src/__tests__/routes.test.ts:2443
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'pending' },
  apps/research-agent/src/__tests__/routes.test.ts:2600
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/routes.test.ts:2604
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > model: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/routes.test.ts:2634
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/routes.test.ts:2638
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > model: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/routes.test.ts:2702
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > data: encodePubSubMessage(createLlmCallEvent({ model: 'gemini-2.5-pro' })),
  apps/research-agent/src/__tests__/routes.test.ts:2716
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > expect(failures[0]?.model).toBe('gemini-2.5-pro');
  apps/research-agent/src/__tests__/routes.test.ts:2754
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/routes.test.ts:2755
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/routes.test.ts:2756
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > llmResults: [{ provider: 'google', model: 'gemini-2.5-pro', status: 'pending' }],
  apps/research-agent/src/__tests__/routes.test.ts:2788
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/routes.test.ts:2789
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/routes.test.ts:2790
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > llmResults: [{ provider: 'google', model: 'gemini-2.5-pro', status: 'pending' }],
  apps/research-agent/src/__tests__/routes.test.ts:2821
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/routes.test.ts:2822
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/routes.test.ts:2823
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > llmResults: [{ provider: 'google', model: 'gemini-2.5-pro', status: 'pending' }],
  apps/research-agent/src/__tests__/routes.test.ts:2850
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/routes.test.ts:2851
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > llmResults: [{ provider: 'google', model: 'gemini-2.5-pro', status: 'pending' }],
  apps/research-agent/src/__tests__/routes.test.ts:2879
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/routes.test.ts:2879
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/routes.test.ts:2881
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > { provider: 'google', model: 'gemini-2.5-pro', status: 'completed', result: 'Done' },
  apps/research-agent/src/__tests__/routes.test.ts:2882
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'pending' },
  apps/research-agent/src/__tests__/routes.test.ts:2894
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > data: encodePubSubMessage(createLlmCallEvent({ model: 'o4-mini-deep-research' })),
  apps/research-agent/src/__tests__/routes.test.ts:2905
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > expect(updatedResearch?.partialFailure?.failedModels).toContain('o4-mini-deep-research');
  apps/research-agent/src/__tests__/routes.test.ts:2912
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/routes.test.ts:2912
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research'],
  apps/research-agent/src/__tests__/routes.test.ts:2916
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > model: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/routes.test.ts:2920
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'pending' },
  apps/research-agent/src/__tests__/routes.test.ts:2932
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > data: encodePubSubMessage(createLlmCallEvent({ model: 'o4-mini-deep-research' })),
  apps/research-agent/src/__tests__/routes.test.ts:2943
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > expect(updatedResearch?.partialFailure?.failedModels).toContain('gemini-2.5-pro');
  apps/research-agent/src/__tests__/routes.test.ts:2953
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/routes.test.ts:2954
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > synthesisModel: 'claude-opus-4-5-20251101',
  apps/research-agent/src/__tests__/routes.test.ts:2955
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > llmResults: [{ provider: 'google', model: 'gemini-2.5-pro', status: 'pending' }],
  apps/research-agent/src/__tests__/usecases.test.ts:21
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/usecases.test.ts:22
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/usecases.test.ts:48
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/usecases.test.ts:48
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/usecases.test.ts:49
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/usecases.test.ts:63
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > expect(result.value.selectedModels).toEqual(['gemini-2.5-pro', 'claude-opus-4-5-20251101']);
  apps/research-agent/src/__tests__/usecases.test.ts:63
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > expect(result.value.selectedModels).toEqual(['gemini-2.5-pro', 'claude-opus-4-5-20251101']);
  apps/research-agent/src/__tests__/usecases.test.ts:73
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/usecases.test.ts:73
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/usecases.test.ts:73
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro', 'o4-mini-deep-research', 'claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/usecases.test.ts:74
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/usecases.test.ts:99
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/usecases.test.ts:100
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/usecases.test.ts:119
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > selectedModels: ['gemini-2.5-pro'],
  apps/research-agent/src/__tests__/usecases.test.ts:120
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/usecases.test.ts:140
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > selectedModels: ['claude-opus-4-5-20251101'],
  apps/research-agent/src/__tests__/usecases.test.ts:141
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: 'gemini-2.5-pro',
  apps/research-agent/src/__tests__/usecases.test.ts:151
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > expect(result.value.llmResults[0]?.model).toBe('claude-opus-4-5-20251101');
  apps/research-agent/src/domain/research/usecases/processResearch.ts:63
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > deps.titleGenerator !== undefined ? 'gemini-2.5-flash' : research.synthesisModel;
  apps/research-agent/src/domain/research/usecases/processResearch.ts:93
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > deps.reportLlmSuccess('gemini-2.5-flash');
  apps/research-agent/src/domain/research/usecases/runSynthesis.ts:283
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > type ImageModel = 'gpt-image-1' | 'gemini-2.5-flash-image';
  apps/research-agent/src/domain/research/usecases/runSynthesis.ts:283
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > type ImageModel = 'gpt-image-1' | 'gemini-2.5-flash-image';
  apps/research-agent/src/domain/research/usecases/runSynthesis.ts:301
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > if (hasOpenAiKey) return 'gpt-image-1';
  apps/research-agent/src/domain/research/usecases/runSynthesis.ts:302
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > if (hasGoogleKey) return 'gemini-2.5-flash-image';
  apps/research-agent/src/domain/research/usecases/runSynthesis.ts:304
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > if (hasGoogleKey) return 'gemini-2.5-flash-image';
  apps/research-agent/src/domain/research/usecases/runSynthesis.ts:305
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > if (hasOpenAiKey) return 'gpt-image-1';
  apps/research-agent/src/domain/research/usecases/runSynthesis.ts:319
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > const promptModel = 'gemini-2.5-pro';
  apps/research-agent/src/index.ts:27
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > 'gemini-2.5-pro',
  apps/research-agent/src/index.ts:28
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > 'gemini-2.5-flash',
  apps/research-agent/src/index.ts:29
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > 'claude-opus-4-5-20251101',
  apps/research-agent/src/index.ts:30
    Hardcoded model string 'claude-sonnet-4-5-20250929'. Use LlmModels constant instead.
    > 'claude-sonnet-4-5-20250929',
  apps/research-agent/src/index.ts:31
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > 'o4-mini-deep-research',
  apps/research-agent/src/index.ts:32
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > 'gpt-5.2',
  apps/research-agent/src/index.ts:33
    Hardcoded model string 'sonar'. Use LlmModels constant instead.
    > 'sonar',
  apps/research-agent/src/index.ts:34
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > 'sonar-pro',
  apps/research-agent/src/index.ts:35
    Hardcoded model string 'sonar-deep-research'. Use LlmModels constant instead.
    > 'sonar-deep-research',
  apps/research-agent/src/index.ts:37
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > 'gemini-2.0-flash',
  apps/research-agent/src/infra/image/imageServiceClient.ts:40
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > export type PromptModel = 'gpt-4.1' | 'gemini-2.5-pro';
  apps/research-agent/src/infra/image/imageServiceClient.ts:41
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > export type ImageModel = 'gpt-image-1' | 'gemini-2.5-flash-image';
  apps/research-agent/src/infra/image/imageServiceClient.ts:41
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > export type ImageModel = 'gpt-image-1' | 'gemini-2.5-flash-image';
  apps/research-agent/src/routes/internalRoutes.ts:147
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: body.selectedModels[0] ?? 'gemini-2.5-pro',
  apps/research-agent/src/routes/internalRoutes.ts:321
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > 'gemini-2.5-flash',
  apps/research-agent/src/routes/internalRoutes.ts:324
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > services.pricingContext.getPricing('gemini-2.5-flash')
  apps/research-agent/src/routes/internalRoutes.ts:327
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > 'gemini-2.5-flash',
  apps/research-agent/src/routes/internalRoutes.ts:330
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > services.pricingContext.getPricing('gemini-2.5-flash'),
  apps/research-agent/src/routes/internalRoutes.ts:851
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > 'gemini-2.5-flash',
  apps/research-agent/src/routes/internalRoutes.ts:854
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > services.pricingContext.getPricing('gemini-2.5-flash'),
  apps/research-agent/src/routes/researchRoutes.ts:101
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.5-flash',
  apps/research-agent/src/routes/researchRoutes.ts:112
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > const generator = createTitleGenerator('gemini-2.5-flash', googleApiKey, userId, pricing);
  apps/research-agent/src/routes/researchRoutes.ts:167
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: body.synthesisModel ?? body.selectedModels[0] ?? 'gemini-2.5-pro',
  apps/research-agent/src/routes/researchRoutes.ts:175
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > pricingContext.getPricing('gemini-2.5-flash')
  apps/research-agent/src/routes/researchRoutes.ts:232
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > 'gemini-2.5-flash',
  apps/research-agent/src/routes/researchRoutes.ts:235
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > pricingContext.getPricing('gemini-2.5-flash')
  apps/research-agent/src/routes/researchRoutes.ts:246
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > 'gemini-2.5-pro',
  apps/research-agent/src/routes/researchRoutes.ts:247
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > 'claude-opus-4-5-20251101',
  apps/research-agent/src/routes/researchRoutes.ts:248
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > 'o4-mini-deep-research',
  apps/research-agent/src/routes/researchRoutes.ts:257
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > synthesisModel: body.synthesisModel ?? resolvedSelectedModels[0] ?? 'gemini-2.5-pro',
  apps/research-agent/src/routes/researchRoutes.ts:265
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > pricingContext.getPricing('gemini-2.5-flash')
  apps/research-agent/src/routes/researchRoutes.ts:348
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > 'gemini-2.5-flash',
  apps/research-agent/src/routes/researchRoutes.ts:351
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > pricingContext.getPricing('gemini-2.5-flash')
  apps/research-agent/src/routes/researchRoutes.ts:376
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > pricingContext.getPricing('gemini-2.5-flash')
  apps/research-agent/src/routes/researchRoutes.ts:652
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > 'gemini-2.5-flash',
  apps/research-agent/src/routes/researchRoutes.ts:655
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > pricingContext.getPricing('gemini-2.5-flash'),
  apps/research-agent/src/routes/researchRoutes.ts:892
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > pricingContext.getPricing('gemini-2.5-flash')
  apps/user-service/src/__tests__/infra/llmValidator.test.ts:62
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  apps/user-service/src/__tests__/infra/llmValidator.test.ts:114
    Hardcoded model string 'gpt-4o-mini'. Use LlmModels constant instead.
    > model: 'gpt-4o-mini',
  apps/user-service/src/__tests__/infra/llmValidator.test.ts:163
    Hardcoded model string 'claude-3-5-haiku-20241022'. Use LlmModels constant instead.
    > model: 'claude-3-5-haiku-20241022',
  apps/user-service/src/__tests__/infra/llmValidator.test.ts:214
    Hardcoded model string 'sonar'. Use LlmModels constant instead.
    > model: 'sonar',
  apps/user-service/src/index.ts:28
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > 'gemini-2.0-flash',
  apps/user-service/src/index.ts:29
    Hardcoded model string 'gpt-4o-mini'. Use LlmModels constant instead.
    > 'gpt-4o-mini',
  apps/user-service/src/index.ts:30
    Hardcoded model string 'claude-3-5-haiku-20241022'. Use LlmModels constant instead.
    > 'claude-3-5-haiku-20241022',
  apps/user-service/src/index.ts:31
    Hardcoded model string 'sonar'. Use LlmModels constant instead.
    > 'sonar',
  apps/user-service/src/infra/llm/LlmValidatorImpl.ts:21
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > google: 'gemini-2.0-flash',
  apps/user-service/src/infra/llm/LlmValidatorImpl.ts:22
    Hardcoded model string 'gpt-4o-mini'. Use LlmModels constant instead.
    > openai: 'gpt-4o-mini',
  apps/user-service/src/infra/llm/LlmValidatorImpl.ts:23
    Hardcoded model string 'claude-3-5-haiku-20241022'. Use LlmModels constant instead.
    > anthropic: 'claude-3-5-haiku-20241022',
  apps/user-service/src/infra/llm/LlmValidatorImpl.ts:24
    Hardcoded model string 'sonar'. Use LlmModels constant instead.
    > perplexity: 'sonar',
  apps/user-service/src/services.ts:66
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > google: pricingContext.getPricing('gemini-2.0-flash'),
  apps/user-service/src/services.ts:67
    Hardcoded model string 'gpt-4o-mini'. Use LlmModels constant instead.
    > openai: pricingContext.getPricing('gpt-4o-mini'),
  apps/user-service/src/services.ts:68
    Hardcoded model string 'claude-3-5-haiku-20241022'. Use LlmModels constant instead.
    > anthropic: pricingContext.getPricing('claude-3-5-haiku-20241022'),
  apps/user-service/src/services.ts:69
    Hardcoded model string 'sonar'. Use LlmModels constant instead.
    > perplexity: pricingContext.getPricing('sonar'),
  apps/web/src/components/ModelSelector.tsx:20
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > { id: 'gemini-2.5-flash', name: 'Gemini Flash' },
  apps/web/src/components/ModelSelector.tsx:21
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > { id: 'gemini-2.5-pro', name: 'Gemini Pro' },
  apps/web/src/components/ModelSelector.tsx:28
    Hardcoded model string 'claude-sonnet-4-5-20250929'. Use LlmModels constant instead.
    > { id: 'claude-sonnet-4-5-20250929', name: 'Claude Sonnet' },
  apps/web/src/components/ModelSelector.tsx:29
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > { id: 'claude-opus-4-5-20251101', name: 'Claude Opus' },
  apps/web/src/components/ModelSelector.tsx:36
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > { id: 'gpt-5.2', name: 'GPT-5.2' },
  apps/web/src/components/ModelSelector.tsx:37
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > { id: 'o4-mini-deep-research', name: 'O4 Mini' },
  apps/web/src/components/ModelSelector.tsx:44
    Hardcoded model string 'sonar'. Use LlmModels constant instead.
    > { id: 'sonar', name: 'Sonar' },
  apps/web/src/components/ModelSelector.tsx:45
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > { id: 'sonar-pro', name: 'Sonar Pro' },
  apps/web/src/components/ModelSelector.tsx:46
    Hardcoded model string 'sonar-deep-research'. Use LlmModels constant instead.
    > { id: 'sonar-deep-research', name: 'Deep Research' },
  apps/web/src/pages/ResearchAgentPage.tsx:25
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > const SYNTHESIS_CAPABLE_MODELS: SupportedModel[] = ['gemini-2.5-pro', 'gpt-5.2'];
  apps/web/src/pages/ResearchAgentPage.tsx:25
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > const SYNTHESIS_CAPABLE_MODELS: SupportedModel[] = ['gemini-2.5-pro', 'gpt-5.2'];
  apps/web/src/pages/ResearchDetailPage.tsx:208
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > const SYNTHESIS_CAPABLE_MODELS: SupportedModel[] = ['gemini-2.5-pro', 'gpt-5.2'];
  apps/web/src/pages/ResearchDetailPage.tsx:208
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > const SYNTHESIS_CAPABLE_MODELS: SupportedModel[] = ['gemini-2.5-pro', 'gpt-5.2'];
  apps/web/src/services/ResearchAgentApi.types.ts:8
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > | 'gemini-2.5-pro'
  apps/web/src/services/ResearchAgentApi.types.ts:9
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > | 'gemini-2.5-flash'
  apps/web/src/services/ResearchAgentApi.types.ts:10
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > | 'claude-opus-4-5-20251101'
  apps/web/src/services/ResearchAgentApi.types.ts:11
    Hardcoded model string 'claude-sonnet-4-5-20250929'. Use LlmModels constant instead.
    > | 'claude-sonnet-4-5-20250929'
  apps/web/src/services/ResearchAgentApi.types.ts:12
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > | 'o4-mini-deep-research'
  apps/web/src/services/ResearchAgentApi.types.ts:13
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > | 'gpt-5.2'
  apps/web/src/services/ResearchAgentApi.types.ts:14
    Hardcoded model string 'sonar'. Use LlmModels constant instead.
    > | 'sonar'
  apps/web/src/services/ResearchAgentApi.types.ts:15
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > | 'sonar-pro'
  apps/web/src/services/ResearchAgentApi.types.ts:16
    Hardcoded model string 'sonar-deep-research'. Use LlmModels constant instead.
    > | 'sonar-deep-research';
  apps/web/src/services/ResearchAgentApi.types.ts:19
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > 'gemini-2.5-pro': 'google',
  apps/web/src/services/ResearchAgentApi.types.ts:20
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > 'gemini-2.5-flash': 'google',
  apps/web/src/services/ResearchAgentApi.types.ts:21
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > 'claude-opus-4-5-20251101': 'anthropic',
  apps/web/src/services/ResearchAgentApi.types.ts:22
    Hardcoded model string 'claude-sonnet-4-5-20250929'. Use LlmModels constant instead.
    > 'claude-sonnet-4-5-20250929': 'anthropic',
  apps/web/src/services/ResearchAgentApi.types.ts:23
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > 'o4-mini-deep-research': 'openai',
  apps/web/src/services/ResearchAgentApi.types.ts:24
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > 'gpt-5.2': 'openai',
  apps/web/src/services/ResearchAgentApi.types.ts:26
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > 'sonar-pro': 'perplexity',
  apps/web/src/services/ResearchAgentApi.types.ts:27
    Hardcoded model string 'sonar-deep-research'. Use LlmModels constant instead.
    > 'sonar-deep-research': 'perplexity',
  packages/infra-gemini/src/__tests__/client.test.ts:27
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > const TEST_MODEL = 'gemini-2.5-flash';
  packages/infra-gemini/src/__tests__/client.test.ts:397
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > expect(result.value.model).toBe('gemini-2.5-flash-image');
  packages/infra-gemini/src/client.ts:31
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > const IMAGE_MODEL = 'gemini-2.5-flash-image';
  packages/infra-gpt/src/__tests__/client.test.ts:408
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > expect(result.value.model).toBe('gpt-image-1');
  packages/infra-gpt/src/client.ts:32
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > const IMAGE_MODEL = 'gpt-image-1';
  packages/infra-perplexity/src/__tests__/client.test.ts:20
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > const TEST_MODEL = 'sonar-pro';
  packages/infra-perplexity/src/client.ts:36
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > 'sonar-pro': 'medium',
  packages/infra-perplexity/src/client.ts:37
    Hardcoded model string 'sonar-deep-research'. Use LlmModels constant instead.
    > 'sonar-deep-research': 'high',
  packages/llm-audit/src/__tests__/audit.test.ts:405
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > model: 'sonar-pro',
  packages/llm-audit/src/__tests__/audit.test.ts:423
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  packages/llm-audit/src/__tests__/audit.test.ts:441
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  packages/llm-audit/src/__tests__/audit.test.ts:447
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > await ctx.success({ response: '[image]', imageModel: 'gpt-image-1' });
  packages/llm-audit/src/__tests__/audit.test.ts:451
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > imageModel: 'gpt-image-1',
  packages/llm-audit/src/__tests__/audit.test.ts:459
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > model: 'gemini-2.5-flash-image',
  packages/llm-audit/src/__tests__/audit.test.ts:477
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > model: 'gpt-image-1',
  packages/llm-audit/src/__tests__/audit.test.ts:495
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > model: 'gemini-2.5-flash-image',
  packages/llm-audit/src/__tests__/audit.test.ts:504
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > imageModel: 'gemini-2.5-flash-image',
  packages/llm-audit/src/__tests__/audit.test.ts:512
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > imageModel: 'gemini-2.5-flash-image',
  packages/llm-pricing/src/__tests__/costCalculator.test.ts:11
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.0-flash',
  packages/llm-pricing/src/__tests__/costCalculator.test.ts:57
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > model: 'sonar-pro',
  packages/llm-pricing/src/__tests__/costCalculator.test.ts:181
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > model: 'gemini-2.5-pro',
  packages/llm-pricing/src/__tests__/costCalculator.test.ts:230
    Hardcoded model string 'sonar'. Use LlmModels constant instead.
    > model: 'sonar',
  packages/llm-pricing/src/__tests__/costCalculator.test.ts:248
    Hardcoded model string 'sonar'. Use LlmModels constant instead.
    > model: 'sonar',
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:9
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > 'gemini-2.5-pro': {
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:14
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > 'gemini-2.5-flash': {
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:19
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > 'gemini-2.0-flash': {
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:24
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > 'gemini-2.5-flash-image': {
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:36
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > 'o4-mini-deep-research': {
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:42
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > 'gpt-5.2': {
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:47
    Hardcoded model string 'gpt-4o-mini'. Use LlmModels constant instead.
    > 'gpt-4o-mini': {
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:52
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > 'gpt-image-1': {
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:64
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > 'claude-opus-4-5-20251101': {
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:71
    Hardcoded model string 'claude-sonnet-4-5-20250929'. Use LlmModels constant instead.
    > 'claude-sonnet-4-5-20250929': {
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:78
    Hardcoded model string 'claude-3-5-haiku-20241022'. Use LlmModels constant instead.
    > 'claude-3-5-haiku-20241022': {
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:96
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > 'sonar-pro': {
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:101
    Hardcoded model string 'sonar-deep-research'. Use LlmModels constant instead.
    > 'sonar-deep-research': {
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:121
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > expect(context.hasPricing('gemini-2.5-pro')).toBe(true);
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:122
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > expect(context.hasPricing('gpt-5.2')).toBe(true);
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:123
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > expect(context.hasPricing('claude-opus-4-5-20251101')).toBe(true);
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:124
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > expect(context.hasPricing('sonar-pro')).toBe(true);
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:130
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > const pricing = context.getPricing('gemini-2.5-pro');
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:139
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > expect(() => context.getPricing('unknown-model' as 'gemini-2.5-pro')).toThrow('Pricing not found');
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:146
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > context.validateModels(['gemini-2.5-pro', 'gpt-5.2'])
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:146
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > context.validateModels(['gemini-2.5-pro', 'gpt-5.2'])
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:159
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > expect(() => context.validateModels(['gemini-2.5-pro', 'gpt-5.2'])).toThrow(
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:159
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > expect(() => context.validateModels(['gemini-2.5-pro', 'gpt-5.2'])).toThrow(
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:169
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > expect(models).toContain('gemini-2.5-pro');
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:170
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > expect(models).toContain('gpt-5.2');
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:191
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > const geminiFlashPricing = mockGooglePricing.models['gemini-2.5-flash'];
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:199
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > 'gemini-2.5-flash': geminiFlashPricing,
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:210
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > createPricingContext(partialPricing, ['gemini-2.5-flash'])
  packages/llm-pricing/src/__tests__/usageLogger.test.ts:73
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.5-flash',
  packages/llm-pricing/src/__tests__/usageLogger.test.ts:143
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > expect(mockCollection.doc).toHaveBeenCalledWith('gemini-2.5-flash');
  packages/llm-pricing/src/__tests__/usageLogger.test.ts:155
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > (call) => call[1]?.model === 'gemini-2.5-flash' && call[1]?.provider === 'google'
  packages/llm-pricing/src/__tests__/usageLogger.test.ts:159
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > model: 'gemini-2.5-flash',
  packages/llm-pricing/src/testFixtures.ts:44
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > if (model === 'gpt-image-1' || model === 'gemini-2.5-flash-image') {
  packages/llm-pricing/src/testFixtures.ts:44
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > if (model === 'gpt-image-1' || model === 'gemini-2.5-flash-image') {
  packages/llm-pricing/src/testFixtures.ts:64
    Hardcoded model string 'gemini-2.5-pro'. Use LlmModels constant instead.
    > 'gemini-2.5-pro',
  packages/llm-pricing/src/testFixtures.ts:65
    Hardcoded model string 'gemini-2.5-flash'. Use LlmModels constant instead.
    > 'gemini-2.5-flash',
  packages/llm-pricing/src/testFixtures.ts:66
    Hardcoded model string 'gemini-2.0-flash'. Use LlmModels constant instead.
    > 'gemini-2.0-flash',
  packages/llm-pricing/src/testFixtures.ts:67
    Hardcoded model string 'gemini-2.5-flash-image'. Use LlmModels constant instead.
    > 'gemini-2.5-flash-image',
  packages/llm-pricing/src/testFixtures.ts:68
    Hardcoded model string 'o4-mini-deep-research'. Use LlmModels constant instead.
    > 'o4-mini-deep-research',
  packages/llm-pricing/src/testFixtures.ts:69
    Hardcoded model string 'gpt-5.2'. Use LlmModels constant instead.
    > 'gpt-5.2',
  packages/llm-pricing/src/testFixtures.ts:70
    Hardcoded model string 'gpt-4o-mini'. Use LlmModels constant instead.
    > 'gpt-4o-mini',
  packages/llm-pricing/src/testFixtures.ts:71
    Hardcoded model string 'gpt-image-1'. Use LlmModels constant instead.
    > 'gpt-image-1',
  packages/llm-pricing/src/testFixtures.ts:72
    Hardcoded model string 'claude-opus-4-5-20251101'. Use LlmModels constant instead.
    > 'claude-opus-4-5-20251101',
  packages/llm-pricing/src/testFixtures.ts:73
    Hardcoded model string 'claude-sonnet-4-5-20250929'. Use LlmModels constant instead.
    > 'claude-sonnet-4-5-20250929',
  packages/llm-pricing/src/testFixtures.ts:74
    Hardcoded model string 'claude-3-5-haiku-20241022'. Use LlmModels constant instead.
    > 'claude-3-5-haiku-20241022',
  packages/llm-pricing/src/testFixtures.ts:75
    Hardcoded model string 'sonar'. Use LlmModels constant instead.
    > 'sonar',
  packages/llm-pricing/src/testFixtures.ts:76
    Hardcoded model string 'sonar-pro'. Use LlmModels constant instead.
    > 'sonar-pro',
  packages/llm-pricing/src/testFixtures.ts:77
    Hardcoded model string 'sonar-deep-research'. Use LlmModels constant instead.
    > 'sonar-deep-research',

--- RULE-5 (357 violations) ---
  apps/app-settings-service/src/__tests__/infra/FirestorePricingRepository.test.ts:21
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/app-settings-service/src/__tests__/infra/FirestorePricingRepository.test.ts:38
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > const result = await repo.getByProvider('google');
  apps/app-settings-service/src/__tests__/infra/FirestorePricingRepository.test.ts:41
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > expect(result?.provider).toBe('google');
  apps/app-settings-service/src/__tests__/infra/FirestorePricingRepository.test.ts:54
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > const result = await repo.getByProvider('perplexity');
  apps/app-settings-service/src/__tests__/routes/internalRoutes.test.ts:12
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/app-settings-service/src/__tests__/routes/internalRoutes.test.ts:24
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/app-settings-service/src/__tests__/routes/internalRoutes.test.ts:35
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  apps/app-settings-service/src/__tests__/routes/internalRoutes.test.ts:46
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > provider: 'perplexity',
  apps/app-settings-service/src/__tests__/routes/internalRoutes.test.ts:104
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > expect(body.data.google.provider).toBe('google');
  apps/app-settings-service/src/__tests__/routes/internalRoutes.test.ts:105
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > expect(body.data.openai.provider).toBe('openai');
  apps/app-settings-service/src/__tests__/routes/internalRoutes.test.ts:106
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > expect(body.data.anthropic.provider).toBe('anthropic');
  apps/app-settings-service/src/__tests__/routes/internalRoutes.test.ts:107
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > expect(body.data.perplexity.provider).toBe('perplexity');
  apps/app-settings-service/src/domain/ports/index.ts:5
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  apps/app-settings-service/src/domain/ports/index.ts:5
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  apps/app-settings-service/src/domain/ports/index.ts:5
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  apps/app-settings-service/src/domain/ports/index.ts:5
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  apps/app-settings-service/src/index.ts:23
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > pricingRepository.getByProvider('google'),
  apps/app-settings-service/src/index.ts:24
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > pricingRepository.getByProvider('openai'),
  apps/app-settings-service/src/index.ts:25
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > pricingRepository.getByProvider('anthropic'),
  apps/app-settings-service/src/index.ts:26
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > pricingRepository.getByProvider('perplexity'),
  apps/app-settings-service/src/routes/internalRoutes.ts:70
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > pricingRepository.getByProvider('google'),
  apps/app-settings-service/src/routes/internalRoutes.ts:71
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > pricingRepository.getByProvider('openai'),
  apps/app-settings-service/src/routes/internalRoutes.ts:72
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > pricingRepository.getByProvider('anthropic'),
  apps/app-settings-service/src/routes/internalRoutes.ts:73
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > pricingRepository.getByProvider('perplexity'),
  apps/app-settings-service/src/routes/publicRoutes.ts:68
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > pricingRepository.getByProvider('google'),
  apps/app-settings-service/src/routes/publicRoutes.ts:69
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > pricingRepository.getByProvider('openai'),
  apps/app-settings-service/src/routes/publicRoutes.ts:70
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > pricingRepository.getByProvider('anthropic'),
  apps/app-settings-service/src/routes/publicRoutes.ts:71
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > pricingRepository.getByProvider('perplexity'),
  apps/image-service/src/__tests__/models.test.ts:13
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/image-service/src/__tests__/models.test.ts:20
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/image-service/src/__tests__/models.test.ts:49
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/image-service/src/__tests__/models.test.ts:56
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/image-service/src/domain/models/ImageGenerationModel.ts:4
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'openai' | 'google';
  apps/image-service/src/domain/models/ImageGenerationModel.ts:4
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai' | 'google';
  apps/image-service/src/domain/models/ImageGenerationModel.ts:9
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > 'gpt-image-1': { provider: 'openai', modelId: 'gpt-image-1' },
  apps/image-service/src/domain/models/ImageGenerationModel.ts:10
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > 'gemini-2.5-flash-image': { provider: 'google', modelId: 'gemini-2.5-flash-image' },
  apps/image-service/src/domain/models/ImagePromptModel.ts:1
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai';
  apps/image-service/src/domain/models/ImagePromptModel.ts:1
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai';
  apps/image-service/src/domain/models/ImagePromptModel.ts:10
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > 'gpt-4.1': { provider: 'openai', modelId: 'gpt-4.1' },
  apps/image-service/src/domain/models/ImagePromptModel.ts:11
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > 'gemini-2.5-pro': { provider: 'google', modelId: 'gemini-2.5-pro' },
  apps/image-service/src/services.ts:32
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google' | 'openai',
  apps/image-service/src/services.ts:32
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'google' | 'openai',
  apps/image-service/src/services.ts:86
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google' | 'openai',
  apps/image-service/src/services.ts:86
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'google' | 'openai',
  apps/image-service/src/services.ts:91
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > if (provider === 'google') {
  apps/image-service/src/services.ts:102
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > if (config.provider === 'openai') {
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:46
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.5-pro', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:47
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:88
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.5-pro', status: 'completed', result: 'Result' },
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:89
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:103
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.5-pro', status: 'completed', result: 'Result' },
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:104
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'processing' },
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:119
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:125
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:143
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.5-pro', status: 'failed', error: 'API Error' },
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:145
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:168
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:174
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:205
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:211
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:238
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:243
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'failed', error: 'Error 1' },
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:245
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:267
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:272
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/checkLlmCompletion.test.ts:273
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > { provider: 'anthropic', model: 'claude-opus-4-5-20251101', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:49
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:55
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:289
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:301
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/enhanceResearch.test.ts:310
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:78
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:79
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:186
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:187
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:188
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > { provider: 'anthropic', model: 'claude-sonnet-4-20250514', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:223
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > { provider: 'anthropic', model: 'claude-sonnet-4-5-20250929', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:224
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.5-flash', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:240
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'completed', result: 'Existing' },
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:241
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:242
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > { provider: 'anthropic', model: 'claude-sonnet-4-20250514', status: 'pending' },
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:266
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/processResearch.test.ts:272
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:57
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:62
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'failed', error: 'Rate limit' },
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:124
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:130
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:229
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.5-flash', status: 'completed', result: 'Result' },
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:230
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'failed', error: 'Error 1' },
  apps/research-agent/src/__tests__/domain/research/usecases/retryFailedLlms.test.ts:232
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:84
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:90
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:169
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'completed', result: 'Result' },
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:170
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini', status: 'completed', result: 'Result' },
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:246
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'completed', result: 'Result' },
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:248
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:254
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:281
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:286
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini', status: 'completed', result: 'Result 2' },
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:303
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:308
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini', status: 'completed', result: 'Result 2' },
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:324
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:329
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini', status: 'completed', result: 'Result 2' },
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:346
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'completed', result: 'Result' },
  apps/research-agent/src/__tests__/domain/research/usecases/retryFromFailed.test.ts:347
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini', status: 'failed', error: 'LLM Error' },
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:80
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:86
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:141
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'failed', error: 'Error' },
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:142
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'failed', error: 'Error' },
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:161
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:167
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:172
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'failed', error: 'Error' },
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:295
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'completed' },
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:296
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'gpt-4', status: 'completed', result: 'OpenAI Result' },
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:320
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:344
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:349
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'failed', error: 'Failed' },
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:350
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > { provider: 'anthropic', model: 'claude-opus', status: 'failed', error: 'Failed' },
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:366
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:389
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:395
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:413
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'failed', error: 'Failed' },
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:433
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/usecases/runSynthesis.test.ts:457
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/utils/costCalculator.test.ts:11
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  apps/research-agent/src/__tests__/domain/research/utils/costCalculator.test.ts:62
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > provider: 'perplexity',
  apps/research-agent/src/__tests__/domain/research/utils/costCalculator.test.ts:80
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > provider: 'perplexity',
  apps/research-agent/src/__tests__/domain/research/utils/costCalculator.test.ts:99
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > provider: 'perplexity',
  apps/research-agent/src/__tests__/domain/research/utils/costCalculator.test.ts:113
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  apps/research-agent/src/__tests__/domain/research/utils/costCalculator.test.ts:180
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/domain/research/utils/costCalculator.test.ts:232
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/utils/costCalculator.test.ts:274
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > provider: 'perplexity',
  apps/research-agent/src/__tests__/domain/research/utils/costCalculator.test.ts:298
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  apps/research-agent/src/__tests__/domain/research/utils/costCalculator.test.ts:322
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/domain/research/utils/costCalculator.test.ts:344
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/utils/htmlGenerator.test.ts:87
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/utils/htmlGenerator.test.ts:93
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/domain/research/utils/htmlGenerator.test.ts:116
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/domain/research/utils/htmlGenerator.test.ts:122
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/domain/research/utils/htmlGenerator.test.ts:138
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/infra/notification/NoopNotificationSender.test.ts:33
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > const result = await sender.sendLlmFailure('user-123', 'research-456', 'google', 'API Error');
  apps/research-agent/src/__tests__/infra/notification/NoopNotificationSender.test.ts:41
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > const result = await sender.sendLlmFailure('', '', 'openai', '');
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:15
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:31
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:61
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > const result = await client.getForProvider('openai');
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:72
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > const result = await client.getForProvider('perplexity');
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:81
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > const result = await client.getForProvider('openai');
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:93
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > const result1 = await client.getForProvider('openai');
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:98
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > const result2 = await client.getForProvider('openai');
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:106
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > await client.getForProvider('openai');
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:115
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > const result = await client.getForProvider('openai');
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:131
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > await client.getForProvider('openai');
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:140
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > const result = await client.getForProvider('openai');
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:152
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > const openaiResult = await client.getForProvider('openai');
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:153
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > const googleResult = await client.getForProvider('google');
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:164
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > const result = await client.getModelPricing('openai', 'gpt-4o');
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:176
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > const result = await client.getModelPricing('perplexity', 'sonar-pro');
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:184
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > const result = await client.getModelPricing('openai', 'gpt-5');
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:195
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > const result1 = await client.getModelPricing('openai', 'gpt-4o');
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:200
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > const result2 = await client.getModelPricing('openai', 'gpt-4o-mini');
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:213
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > await client.getForProvider('openai');
  apps/research-agent/src/__tests__/infra/pricing/PricingClient.test.ts:226
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > const result = await client.getForProvider('openai');
  apps/research-agent/src/__tests__/infra/pricing/firestorePricingRepository.test.ts:40
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > const result = await repository.findByProviderAndModel('google', 'gemini-2.0-flash');
  apps/research-agent/src/__tests__/infra/pricing/firestorePricingRepository.test.ts:53
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/infra/pricing/firestorePricingRepository.test.ts:63
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > const result = await repository.findByProviderAndModel('google', 'gemini-2.0-flash');
  apps/research-agent/src/__tests__/infra/pricing/firestorePricingRepository.test.ts:74
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/infra/pricing/firestorePricingRepository.test.ts:84
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > const result = await repository.findByProviderAndModel('google', 'gemini');
  apps/research-agent/src/__tests__/infra/pricing/firestorePricingRepository.test.ts:87
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/infra/pubsub/analyticsEventPublisher.test.ts:35
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/infra/pubsub/analyticsEventPublisher.test.ts:71
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:312
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.5-pro', status: 'pending' },
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:313
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > { provider: 'anthropic', model: 'claude-opus-4-5-20251101', status: 'pending' },
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:332
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:337
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > { provider: 'anthropic', model: 'claude-opus-4-5-20251101', status: 'pending' },
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:365
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'failed', error: 'Rate limit' },
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:383
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:401
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'failed', error: 'Rate limit' },
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:419
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:436
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > llmResults: [{ provider: 'google', model: 'gemini-2.0-flash', status: 'processing' }],
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:454
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/infra/research/FirestoreResearchRepository.test.ts:472
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > llmResults: [{ provider: 'google', model: 'gemini-2.0-flash', status: 'processing' }],
  apps/research-agent/src/__tests__/infra/user/userServiceClient.test.ts:95
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > await client.reportLlmSuccess('user-1', 'google');
  apps/research-agent/src/__tests__/infra/user/userServiceClient.test.ts:107
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > await expect(client.reportLlmSuccess('user-1', 'openai')).resolves.toBeUndefined();
  apps/research-agent/src/__tests__/infra/user/userServiceClient.test.ts:115
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > await expect(client.reportLlmSuccess('user-1', 'anthropic')).resolves.toBeUndefined();
  apps/research-agent/src/__tests__/routes.test.ts:47
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/routes.test.ts:512
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > expect(body.data.llmResults[0]?.provider).toBe('anthropic');
  apps/research-agent/src/__tests__/routes.test.ts:522
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > llmResults: [{ provider: 'google', model: 'gemini-2.5-pro', status: 'pending' }],
  apps/research-agent/src/__tests__/routes.test.ts:543
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > expect(body.data.llmResults[0]?.provider).toBe('openai');
  apps/research-agent/src/__tests__/routes.test.ts:544
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > expect(body.data.llmResults[1]?.provider).toBe('anthropic');
  apps/research-agent/src/__tests__/routes.test.ts:1081
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/routes.test.ts:1343
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/routes.test.ts:1349
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/routes.test.ts:1505
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.0-flash', status: 'completed', result: 'Result' },
  apps/research-agent/src/__tests__/routes.test.ts:1707
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/routes.test.ts:1713
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/research-agent/src/__tests__/routes.test.ts:1754
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/routes.test.ts:1759
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini', status: 'completed', result: 'Result 2' },
  apps/research-agent/src/__tests__/routes.test.ts:1903
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/routes.test.ts:1908
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini', status: 'completed', result: 'Result 2' },
  apps/research-agent/src/__tests__/routes.test.ts:2327
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/routes.test.ts:2353
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/routes.test.ts:2442
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.5-pro', status: 'pending' },
  apps/research-agent/src/__tests__/routes.test.ts:2443
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'pending' },
  apps/research-agent/src/__tests__/routes.test.ts:2603
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/routes.test.ts:2637
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/routes.test.ts:2745
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > const googleResult = updatedResearch?.llmResults.find((r) => r.provider === 'google');
  apps/research-agent/src/__tests__/routes.test.ts:2756
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > llmResults: [{ provider: 'google', model: 'gemini-2.5-pro', status: 'pending' }],
  apps/research-agent/src/__tests__/routes.test.ts:2790
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > llmResults: [{ provider: 'google', model: 'gemini-2.5-pro', status: 'pending' }],
  apps/research-agent/src/__tests__/routes.test.ts:2823
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > llmResults: [{ provider: 'google', model: 'gemini-2.5-pro', status: 'pending' }],
  apps/research-agent/src/__tests__/routes.test.ts:2851
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > llmResults: [{ provider: 'google', model: 'gemini-2.5-pro', status: 'pending' }],
  apps/research-agent/src/__tests__/routes.test.ts:2881
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > { provider: 'google', model: 'gemini-2.5-pro', status: 'completed', result: 'Done' },
  apps/research-agent/src/__tests__/routes.test.ts:2882
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'pending' },
  apps/research-agent/src/__tests__/routes.test.ts:2915
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/routes.test.ts:2920
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > { provider: 'openai', model: 'o4-mini-deep-research', status: 'pending' },
  apps/research-agent/src/__tests__/routes.test.ts:2944
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > expect(updatedResearch?.llmResults.find((r) => r.provider === 'openai')?.status).toBe(
  apps/research-agent/src/__tests__/routes.test.ts:2955
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > llmResults: [{ provider: 'google', model: 'gemini-2.5-pro', status: 'pending' }],
  apps/research-agent/src/__tests__/usecases.test.ts:26
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/research-agent/src/__tests__/usecases.test.ts:85
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > expect(result.value.llmResults[0]?.provider).toBe('google');
  apps/research-agent/src/__tests__/usecases.test.ts:87
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > expect(result.value.llmResults[1]?.provider).toBe('openai');
  apps/research-agent/src/__tests__/usecases.test.ts:88
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > expect(result.value.llmResults[2]?.provider).toBe('anthropic');
  apps/research-agent/src/domain/research/utils/costCalculator.ts:37
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > if (pricing.provider === 'anthropic') {
  apps/research-agent/src/domain/research/utils/costCalculator.ts:39
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > } else if (pricing.provider === 'openai') {
  apps/research-agent/src/domain/research/utils/costCalculator.ts:41
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > } else if (pricing.provider === 'google') {
  apps/user-service/src/__tests__/infra/userSettingsRepository.test.ts:206
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > const result = await repo.updateLlmApiKey('new-user', 'google', encryptedKey);
  apps/user-service/src/__tests__/infra/userSettingsRepository.test.ts:222
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > const result = await repo.updateLlmApiKey('user-123', 'anthropic', encryptedKey);
  apps/user-service/src/__tests__/infra/userSettingsRepository.test.ts:236
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > const result = await repo.updateLlmApiKey('user-123', 'google', createEncryptedValue('key'));
  apps/user-service/src/__tests__/infra/userSettingsRepository.test.ts:248
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > await repo.updateLlmApiKey('user-123', 'google', createEncryptedValue('google-key'));
  apps/user-service/src/__tests__/infra/userSettingsRepository.test.ts:249
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > await repo.updateLlmApiKey('user-123', 'openai', createEncryptedValue('openai-key'));
  apps/user-service/src/__tests__/infra/userSettingsRepository.test.ts:251
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > const result = await repo.deleteLlmApiKey('user-123', 'google');
  apps/user-service/src/__tests__/infra/userSettingsRepository.test.ts:264
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > await repo.updateLlmApiKey('user-123', 'google', createEncryptedValue('key'));
  apps/user-service/src/__tests__/infra/userSettingsRepository.test.ts:265
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > await repo.updateLlmTestResult('user-123', 'google', {
  apps/user-service/src/__tests__/infra/userSettingsRepository.test.ts:270
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > const result = await repo.deleteLlmApiKey('user-123', 'google');
  apps/user-service/src/__tests__/infra/userSettingsRepository.test.ts:285
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > const result = await repo.deleteLlmApiKey('user-123', 'google');
  apps/user-service/src/__tests__/infra/userSettingsRepository.test.ts:302
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > const result = await repo.updateLlmTestResult('new-user', 'google', testResult);
  apps/user-service/src/__tests__/infra/userSettingsRepository.test.ts:322
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > const result = await repo.updateLlmTestResult('user-123', 'openai', testResult);
  apps/user-service/src/__tests__/infra/userSettingsRepository.test.ts:336
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > const result = await repo.updateLlmTestResult('user-123', 'google', {
  apps/user-service/src/__tests__/infra/userSettingsRepository.test.ts:351
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > const result = await repo.updateLlmLastUsed('new-user', 'google');
  apps/user-service/src/__tests__/infra/userSettingsRepository.test.ts:367
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > const result = await repo.updateLlmLastUsed('user-123', 'openai');
  apps/user-service/src/__tests__/infra/userSettingsRepository.test.ts:381
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > const result = await repo.updateLlmLastUsed('user-123', 'google');
  apps/user-service/src/__tests__/llmKeysRoutes.test.ts:286
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/user-service/src/__tests__/llmKeysRoutes.test.ts:314
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/user-service/src/__tests__/llmKeysRoutes.test.ts:341
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/user-service/src/__tests__/llmKeysRoutes.test.ts:352
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > expect(body.data.provider).toBe('google');
  apps/user-service/src/__tests__/llmKeysRoutes.test.ts:382
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/user-service/src/__tests__/llmKeysRoutes.test.ts:411
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/user-service/src/__tests__/llmKeysRoutes.test.ts:440
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  apps/user-service/src/__tests__/llmKeysRoutes.test.ts:472
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  apps/user-service/src/__tests__/llmKeysRoutes.test.ts:500
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  apps/user-service/src/domain/settings/models/UserSettings.ts:11
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  apps/user-service/src/domain/settings/models/UserSettings.ts:11
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  apps/user-service/src/domain/settings/models/UserSettings.ts:11
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  apps/user-service/src/domain/settings/models/UserSettings.ts:11
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  apps/web/src/pages/LlmPricingPage.tsx:199
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > <ProviderBlock provider="google" pricing={pricing.google} />
  apps/web/src/pages/LlmPricingPage.tsx:200
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > <ProviderBlock provider="openai" pricing={pricing.openai} />
  apps/web/src/pages/LlmPricingPage.tsx:201
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > <ProviderBlock provider="anthropic" pricing={pricing.anthropic} />
  apps/web/src/pages/LlmPricingPage.tsx:202
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > <ProviderBlock provider="perplexity" pricing={pricing.perplexity} />
  apps/web/src/pages/SystemHealthPage.tsx:185
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > const getLlmStatus = (provider: 'google' | 'openai' | 'anthropic'): StatusState => {
  apps/web/src/pages/SystemHealthPage.tsx:185
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > const getLlmStatus = (provider: 'google' | 'openai' | 'anthropic'): StatusState => {
  apps/web/src/pages/SystemHealthPage.tsx:185
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > const getLlmStatus = (provider: 'google' | 'openai' | 'anthropic'): StatusState => {
  apps/web/src/pages/SystemHealthPage.tsx:213
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google' | 'openai' | 'anthropic'
  apps/web/src/pages/SystemHealthPage.tsx:213
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'google' | 'openai' | 'anthropic'
  apps/web/src/pages/SystemHealthPage.tsx:213
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'google' | 'openai' | 'anthropic'
  apps/web/src/pages/SystemHealthPage.tsx:249
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > {renderLlmWidget('Claude (Anthropic)', 'anthropic')}
  apps/web/src/pages/SystemHealthPage.tsx:250
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > {renderLlmWidget('Gemini (Google)', 'google')}
  apps/web/src/pages/SystemHealthPage.tsx:251
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > {renderLlmWidget('GPT (OpenAI)', 'openai')}
  apps/web/src/services/llmKeysApi.types.ts:4
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  apps/web/src/services/llmKeysApi.types.ts:4
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  apps/web/src/services/llmKeysApi.types.ts:4
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  apps/web/src/services/llmKeysApi.types.ts:4
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  apps/web/src/services/ResearchAgentApi.types.ts:5
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  apps/web/src/services/ResearchAgentApi.types.ts:5
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  apps/web/src/services/ResearchAgentApi.types.ts:5
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  apps/web/src/services/ResearchAgentApi.types.ts:5
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  apps/web/src/services/ResearchAgentApi.types.ts:23
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > 'o4-mini-deep-research': 'openai',
  apps/web/src/services/ResearchAgentApi.types.ts:27
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > 'sonar-deep-research': 'perplexity',
  apps/web/src/types/index.ts:627
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  apps/web/src/types/index.ts:627
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  apps/web/src/types/index.ts:627
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  apps/web/src/types/index.ts:627
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  packages/infra-claude/src/client.ts:34
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  packages/infra-claude/src/client.ts:55
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  packages/infra-gemini/src/__tests__/client.test.ts:202
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  packages/infra-gemini/src/client.ts:42
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  packages/infra-gemini/src/client.ts:63
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  packages/infra-gpt/src/__tests__/client.test.ts:217
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/infra-gpt/src/client.ts:43
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/infra-gpt/src/client.ts:64
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/infra-perplexity/src/__tests__/client.test.ts:186
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > provider: 'perplexity',
  packages/infra-perplexity/src/client.ts:48
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > provider: 'perplexity',
  packages/infra-perplexity/src/client.ts:78
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > provider: 'perplexity',
  packages/llm-audit/src/__tests__/audit.test.ts:96
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-audit/src/__tests__/audit.test.ts:108
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-audit/src/__tests__/audit.test.ts:123
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  packages/llm-audit/src/__tests__/audit.test.ts:142
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  packages/llm-audit/src/__tests__/audit.test.ts:163
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-audit/src/__tests__/audit.test.ts:177
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-audit/src/__tests__/audit.test.ts:197
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-audit/src/__tests__/audit.test.ts:217
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-audit/src/__tests__/audit.test.ts:235
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-audit/src/__tests__/audit.test.ts:253
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-audit/src/__tests__/audit.test.ts:271
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  packages/llm-audit/src/__tests__/audit.test.ts:296
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  packages/llm-audit/src/__tests__/audit.test.ts:314
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  packages/llm-audit/src/__tests__/audit.test.ts:332
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-audit/src/__tests__/audit.test.ts:350
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-audit/src/__tests__/audit.test.ts:368
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  packages/llm-audit/src/__tests__/audit.test.ts:386
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  packages/llm-audit/src/__tests__/audit.test.ts:404
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > provider: 'perplexity',
  packages/llm-audit/src/__tests__/audit.test.ts:422
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-audit/src/__tests__/audit.test.ts:440
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-audit/src/__tests__/audit.test.ts:458
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  packages/llm-audit/src/__tests__/audit.test.ts:476
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-audit/src/__tests__/audit.test.ts:494
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  packages/llm-audit/src/__tests__/audit.test.ts:524
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-audit/src/__tests__/audit.test.ts:535
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-audit/src/__tests__/audit.test.ts:549
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  packages/llm-audit/src/__tests__/audit.test.ts:572
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-audit/src/__tests__/audit.test.ts:586
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-audit/src/__tests__/audit.test.ts:601
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-audit/src/__tests__/audit.test.ts:622
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-audit/src/types.ts:5
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  packages/llm-audit/src/types.ts:5
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  packages/llm-audit/src/types.ts:5
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  packages/llm-audit/src/types.ts:5
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  packages/llm-pricing/src/__tests__/costCalculator.test.ts:10
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  packages/llm-pricing/src/__tests__/costCalculator.test.ts:23
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-pricing/src/__tests__/costCalculator.test.ts:36
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  packages/llm-pricing/src/__tests__/costCalculator.test.ts:56
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > provider: 'perplexity',
  packages/llm-pricing/src/__tests__/costCalculator.test.ts:69
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  packages/llm-pricing/src/__tests__/costCalculator.test.ts:131
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-pricing/src/__tests__/costCalculator.test.ts:180
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  packages/llm-pricing/src/__tests__/costCalculator.test.ts:229
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > provider: 'perplexity',
  packages/llm-pricing/src/__tests__/costCalculator.test.ts:247
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > provider: 'perplexity',
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:7
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:34
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > provider: 'openai',
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:62
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > provider: 'anthropic',
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:89
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > provider: 'perplexity',
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:153
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > openai: { provider: 'openai', models: {}, updatedAt: '' },
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:181
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > google: { provider: 'google', models: {}, updatedAt: '' },
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:197
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:203
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > openai: { provider: 'openai', models: {}, updatedAt: '' },
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:204
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > anthropic: { provider: 'anthropic', models: {}, updatedAt: '' },
  packages/llm-pricing/src/__tests__/pricingClient.test.ts:205
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > perplexity: { provider: 'perplexity', models: {}, updatedAt: '' },
  packages/llm-pricing/src/__tests__/usageLogger.test.ts:72
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google' as const,
  packages/llm-pricing/src/__tests__/usageLogger.test.ts:155
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > (call) => call[1]?.model === 'gemini-2.5-flash' && call[1]?.provider === 'google'
  packages/llm-pricing/src/__tests__/usageLogger.test.ts:160
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > provider: 'google',
  packages/llm-pricing/src/costCalculator.ts:35
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > if (pricing.provider === 'anthropic') {
  packages/llm-pricing/src/costCalculator.ts:37
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > } else if (pricing.provider === 'openai') {
  packages/llm-pricing/src/costCalculator.ts:39
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > } else if (pricing.provider === 'google') {
  packages/llm-pricing/src/pricingClient.ts:109
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > for (const provider of ['google', 'openai', 'anthropic', 'perplexity'] as const) {
  packages/llm-pricing/src/pricingClient.ts:109
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > for (const provider of ['google', 'openai', 'anthropic', 'perplexity'] as const) {
  packages/llm-pricing/src/pricingClient.ts:109
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > for (const provider of ['google', 'openai', 'anthropic', 'perplexity'] as const) {
  packages/llm-pricing/src/pricingClient.ts:109
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > for (const provider of ['google', 'openai', 'anthropic', 'perplexity'] as const) {
  packages/llm-pricing/src/types.ts:6
    Hardcoded provider string 'google'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  packages/llm-pricing/src/types.ts:6
    Hardcoded provider string 'openai'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  packages/llm-pricing/src/types.ts:6
    Hardcoded provider string 'anthropic'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';
  packages/llm-pricing/src/types.ts:6
    Hardcoded provider string 'perplexity'. Use LlmProviders constant instead.
    > export type LlmProvider = 'google' | 'openai' | 'anthropic' | 'perplexity';

=== Summary ===
  RULE-4: 703 violation(s)
  RULE-5: 357 violation(s)
  Total: 1060 violation(s)
